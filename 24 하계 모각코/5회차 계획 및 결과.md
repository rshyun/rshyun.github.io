
## 계획

> 날짜 : 2024.08.05 14:00 - 17:00
> 목표 : 모델 학습 방법 숙달
> 계획 : GAN 모델로 이미지 생성 모델 실습

## 결과

### 1. GAN

#### 1 - 1. 개념
* GAN(Generative Adversarial Networks) 은 적대적 생성 신경망이라고 불리며, 실제에 가까운 이미지나 사람이 쓴 것과 같은 글 등 여러 가짜 데이터들을 생성하는 딥러닝 기반 모델.
* 서로 다른 2개의 네트워크인 생성모델 (Generator) 과 판별모델 (Discriminator) 을 적대적으로 학습시키며 실제 데이터와 비슷한 데이터를 생성해내는 모델.
* 생성된 데이터에 정해진 레이블 값이 없기 때문에 비지도 학습 기반 생성 모델로 분류됨.
* 생성 모델의 목적은 진짜 분포에 가까운 가짜 분포를 생성하는 것이고, 판별 모델의 목적은 표본이 가짜 분포에 속하는지 진짜 분포에 속하는지를 결정하는 것임.
* GAN 의 궁극적인 목적은 실제 데이터의 분포에 가까운 가까 데이터를 생성하는 것이따라서 판별 모델이 진짜인지 가짜인지를 한쪽으로 판단하지 못하는 경계, 즉 가짜와 진짜를 0과 1로 보았을 때 0.5 값의 위치에서 가짜 와 진짜를 구별할 수 없는 최적해로 간주하게 됨.

#### 1 - 2. 모델 구조

![[5회차1.png]]

*(출처 : Hamed Alqahtani. 2019. An Analysis Of Evaluation Metric Of GANs)*

* 생성 모델 (G) 는 실제 데이터와 비슷한 데이터를 만들어내도록 학습되며, 판별 모델 (D) 는 실제 데이터와 생성 모델이 생성한 가짜 데이터를 구별하도록 학습됨.
* GAN 의 목적 함수는 게임 이론 타입의 목적 함수로 G, D 2명의 플레이어가 싸우면서 서로 균형점을 찾아가도록 하는 방식임.

![[5회차2.png]]

* 여기서 V(D,G) 의 값은 확률값으로 도출됨.
* 이 수식을 D 의 관점에서 살펴보면 실제 데이터 x를 입력하면 D(x) 가 커지면서 log 값이 커져 높은 확률값이 나오도록 하고, 가짜 데이터 G(z) 를 입력하면 log 값이 작아짐에 따라 낮은 확률값이 나오도록 학습됨. 즉 실제 데이터와 G 가 만든 가짜 데이터를 잘 구분하도록 조금씩 업데이트되는 것.
* 이 수식을 G 의 관점에서 살펴보면 Zero-Mean Gaussian 분포에서 노이즈 z 를 멀레이어 퍼셉트론에 통과시켜 샘플들을 생성하며 이 생성된 가짜 데이터 G(z) 를 D 에 입력했을 때 실제 데이터처럼 확률이 높게 나오도록 학습됨. D(G(z)) 값이 높아지고 전체 확률값이 낮아지도록, 즉 G 가 D가 잘 구분하지 못하는 데이터를 생성하도록 조금씩 업데이트되는 것.
* 실제 학습을 진행할 때 2개의 네트워크를 동시에 학습시키지 않고 하나의 네트워크를 고정한 상태에서 다른 한 네트워크를 업데이트하는 방식으로 따로따로 업데이트함.

### 2. 이미지 데이터셋을 활용하여 실습

#### 2 - 1. 라이브러리 import

```
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.data import Subset
import torch
import torch.nn as nn
import torch.optim as optim
```

#### 2 - 2. 데이터셋 파일 불러오기

```
# 필요한 라이브러리 import
import os
import zipfile

# 파일 다운로드
!wget https://daiv-cnu.duckdns.org/contest/ai_competition[2024]_basic/dataset/datasets.zip -O /content/datasets.zip

# 압축 파일 경로
zip_file_path = "/content/datasets.zip"

# 압축 풀 위치
extract_folder = "/content/datasets"

# 압축 파일 풀기
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_folder)

# 압축이 풀린 디렉터리의 내용 확인
print("압축이 풀린 디렉터리 내용:")
os.listdir(extract_folder)
```

#### 2 - 3. 데이터 전처리

```
# 데이터 전처리
transform = transforms.Compose([
    transforms.Resize((64, 64)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

# 데이터셋 경로
dataset_dir = "/content/datasets"

# 데이터셋 생성
dataset = datasets.ImageFolder(root=dataset_dir, transform=transform)

# 이미지 폴더 경로 설정 (상위폴더)
data_dir = "/content/datasets/valid"

# ImageFolder 데이터셋 생성
dataset = datasets.ImageFolder(root=data_dir, transform=transform)

# 클래스 이름 확인
class_names = dataset.classes
print("클래스 이름:", class_names)
```

```
# 원하는 클래스 이름
target_classes = ['Egg'] 

# 선택한 클래스의 인덱스 가져오기
target_indices = [class_names.index(cls) for cls in target_classes]

# 선택한 클래스의 인덱스를 가지는 데이터만 필터링
selected_indices = [i for i, (_, label) in enumerate(dataset) if label in target_indices]

# 서브셋 생성
subset = Subset(dataset, selected_indices)

# 데이터 로더 설정
dataloader = DataLoader(subset, batch_size=32, shuffle=True)

# 데이터셋 샘플 확인
for images, labels in dataloader:
    print("이미지 크기:", images.size())
    print("레이블:", labels)
    break
```

#### 2 - 4. 생성모델

```
class Generator(nn.Module):
    def __init__(self, noise_dim, num_classes, img_size):
        super(Generator, self).__init__()
        self.label_emb = nn.Embedding(num_classes, noise_dim)
        self.model = nn.Sequential(
            nn.Linear(noise_dim * 2, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Linear(512, img_size * img_size * 3),
            nn.Tanh()
        )
        self.img_size = img_size

    def forward(self, noise, labels):
        label_embedding = self.label_emb(labels)
        x = torch.cat((noise, label_embedding), dim=1)
        img = self.model(x)
        img = img.view(img.size(0), 3, self.img_size, self.img_size)
        return img
```

#### 2 - 5. 판별모델

```
class Discriminator(nn.Module):
    def __init__(self, num_classes, img_size):
        super(Discriminator, self).__init__()
        self.label_embedding = nn.Embedding(num_classes, img_size * img_size * 3)
        self.model = nn.Sequential(
            nn.Linear(img_size * img_size * 3 * 2, 512),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(256, 128),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )

    def forward(self, img, labels):
        label_embedding = self.label_embedding(labels)
        label_embedding = label_embedding.view(label_embedding.size(0), -1)
        img_flat = img.view(img.size(0), -1)
        x = torch.cat((img_flat, label_embedding), dim=1)
        validity = self.model(x)
        return validity
```

#### 2 - 6. 최적화 설정

```
# 하이퍼파라미터 설정

noise_dim = 100
num_classes = len(class_names)
img_size = 64
batch_size = 32
lr = 0.0002
num_epochs = 500
```

```
# 모델 초기화

generator = Generator(noise_dim, num_classes, img_size).to(device)
discriminator = Discriminator(num_classes, img_size).to(device)
```

```
# 손실 함수 및 옵티마이저 설정

adversarial_loss = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))
```

#### 2 - 7. 학습

```
# 학습 루프

for epoch in range(num_epochs):
    for i, (real_images, labels) in enumerate(dataloader):
        batch_size = real_images.size(0)
        real_images = real_images.to(device)
        labels = labels.to(device)

        # 판별자 학습
        optimizer_D.zero_grad()
        real_labels = torch.ones(batch_size, 1).to(device)
        fake_labels = torch.zeros(batch_size, 1).to(device)

        # 진짜 이미지 학습
        outputs = discriminator(real_images, labels)
        d_loss_real = adversarial_loss(outputs, real_labels)

        # 가짜 이미지 학습
        noise = torch.randn(batch_size, noise_dim).to(device)
        generated_labels = torch.randint(0, num_classes, (batch_size,)).to(device)
        fake_images = generator(noise, generated_labels)
        outputs = discriminator(fake_images.detach(), generated_labels)
        d_loss_fake = adversarial_loss(outputs, fake_labels)

        # 총 판별자 손실
        d_loss = d_loss_real + d_loss_fake
        d_loss.backward()
        optimizer_D.step()

        # 생성자 학습
        optimizer_G.zero_grad()
        outputs = discriminator(fake_images, generated_labels)
        g_loss = adversarial_loss(outputs, real_labels)
        g_loss.backward()
        optimizer_G.step()

        if i % 100 == 0:
            print(f"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], "
                  f"D Loss: {d_loss.item()}, G Loss: {g_loss.item()}")
```

#### 2 - 8. 생성된 이미지 시각화

```
import matplotlib.pyplot as plt
import numpy as np
import torchvision
```

```
# 생성된 이미지 시각화

generator.eval()
with torch.no_grad():
    noise = torch.randn(16, noise_dim).to(device)
    sample_labels = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5]).to(device)  # 예시 레이블
    generated_images = generator(noise, sample_labels).cpu()
    generated_images = generated_images * 0.5 + 0.5  # 정규화 해제
    grid_img = np.transpose(torchvision.utils.make_grid(generated_images, nrow=4), (1, 2, 0))

plt.figure(figsize=(8, 8))
plt.imshow(grid_img)
plt.axis('off')
plt.show()
```

![[생성결과물.png]]

*위 코드를 학습 시킨 후 생성된 결과물.*

https://colab.research.google.com/drive/1YBLarKOzyMRdLmkkanHMwbgj040KDZsJ?usp=sharing